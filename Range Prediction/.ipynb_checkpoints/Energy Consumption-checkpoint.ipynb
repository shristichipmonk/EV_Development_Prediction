{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fafe664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 71.7950 - mae: 71.7950 - val_loss: 69.9492 - val_mae: 69.9492\n",
      "Epoch 2/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 68.6476 - mae: 68.6476 - val_loss: 65.3084 - val_mae: 65.3084\n",
      "Epoch 3/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 63.4212 - mae: 63.4212 - val_loss: 58.3483 - val_mae: 58.3483\n",
      "Epoch 4/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 56.0920 - mae: 56.0920 - val_loss: 50.5774 - val_mae: 50.5774\n",
      "Epoch 5/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 48.3636 - mae: 48.3636 - val_loss: 42.8563 - val_mae: 42.8563\n",
      "Epoch 6/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 40.0287 - mae: 40.0287 - val_loss: 35.2334 - val_mae: 35.2334\n",
      "Epoch 7/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 32.0598 - mae: 32.0598 - val_loss: 27.6325 - val_mae: 27.6325\n",
      "Epoch 8/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 24.5868 - mae: 24.5868 - val_loss: 20.6259 - val_mae: 20.6259\n",
      "Epoch 9/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 18.6055 - mae: 18.6055 - val_loss: 16.1954 - val_mae: 16.1954\n",
      "Epoch 10/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15.1613 - mae: 15.1613 - val_loss: 14.0039 - val_mae: 14.0039\n",
      "Epoch 11/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.1740 - mae: 13.1740 - val_loss: 12.7781 - val_mae: 12.7781\n",
      "Epoch 12/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11.8944 - mae: 11.8944 - val_loss: 11.8308 - val_mae: 11.8308\n",
      "Epoch 13/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11.1652 - mae: 11.1652 - val_loss: 11.0760 - val_mae: 11.0760\n",
      "Epoch 14/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.6244 - mae: 10.6244 - val_loss: 10.4745 - val_mae: 10.4745\n",
      "Epoch 15/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.0612 - mae: 10.0612 - val_loss: 9.9641 - val_mae: 9.9641\n",
      "Epoch 16/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5996 - mae: 9.5996 - val_loss: 9.5018 - val_mae: 9.5018\n",
      "Epoch 17/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8948 - mae: 8.8948 - val_loss: 9.0935 - val_mae: 9.0935\n",
      "Epoch 18/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.5062 - mae: 8.5062 - val_loss: 8.6930 - val_mae: 8.6930\n",
      "Epoch 19/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1224 - mae: 8.1224 - val_loss: 8.2929 - val_mae: 8.2929\n",
      "Epoch 20/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8860 - mae: 7.8860 - val_loss: 7.9129 - val_mae: 7.9129\n",
      "Epoch 21/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3235 - mae: 7.3235 - val_loss: 7.5500 - val_mae: 7.5500\n",
      "Epoch 22/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9339 - mae: 6.9339 - val_loss: 7.1622 - val_mae: 7.1622\n",
      "Epoch 23/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.7676 - mae: 6.7676 - val_loss: 6.7640 - val_mae: 6.7640\n",
      "Epoch 24/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.2639 - mae: 6.2639 - val_loss: 6.4101 - val_mae: 6.4101\n",
      "Epoch 25/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.9267 - mae: 5.9267 - val_loss: 6.0579 - val_mae: 6.0579\n",
      "Epoch 26/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6398 - mae: 5.6398 - val_loss: 5.7037 - val_mae: 5.7037\n",
      "Epoch 27/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2175 - mae: 5.2175 - val_loss: 5.3783 - val_mae: 5.3783\n",
      "Epoch 28/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0211 - mae: 5.0211 - val_loss: 5.0477 - val_mae: 5.0477\n",
      "Epoch 29/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8747 - mae: 4.8747 - val_loss: 4.7501 - val_mae: 4.7501\n",
      "Epoch 30/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4162 - mae: 4.4162 - val_loss: 4.4508 - val_mae: 4.4508\n",
      "Epoch 31/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.1548 - mae: 4.1548 - val_loss: 4.1752 - val_mae: 4.1752\n",
      "Epoch 32/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9316 - mae: 3.9316 - val_loss: 3.9084 - val_mae: 3.9084\n",
      "Epoch 33/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6798 - mae: 3.6798 - val_loss: 3.6635 - val_mae: 3.6635\n",
      "Epoch 34/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4321 - mae: 3.4321 - val_loss: 3.4163 - val_mae: 3.4163\n",
      "Epoch 35/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.1820 - mae: 3.1820 - val_loss: 3.1887 - val_mae: 3.1887\n",
      "Epoch 36/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.9996 - mae: 2.9996 - val_loss: 2.9976 - val_mae: 2.9976\n",
      "Epoch 37/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7835 - mae: 2.7835 - val_loss: 2.8098 - val_mae: 2.8098\n",
      "Epoch 38/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7110 - mae: 2.7110 - val_loss: 2.6500 - val_mae: 2.6500\n",
      "Epoch 39/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.5105 - mae: 2.5105 - val_loss: 2.5060 - val_mae: 2.5060\n",
      "Epoch 40/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.4009 - mae: 2.4009 - val_loss: 2.3890 - val_mae: 2.3890\n",
      "Epoch 41/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.3271 - mae: 2.3271 - val_loss: 2.2796 - val_mae: 2.2796\n",
      "Epoch 42/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0966 - mae: 2.0966 - val_loss: 2.1691 - val_mae: 2.1691\n",
      "Epoch 43/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0470 - mae: 2.0470 - val_loss: 2.1084 - val_mae: 2.1084\n",
      "Epoch 44/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9887 - mae: 1.9887 - val_loss: 1.9967 - val_mae: 1.9967\n",
      "Epoch 45/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8755 - mae: 1.8755 - val_loss: 1.9157 - val_mae: 1.9157\n",
      "Epoch 46/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8430 - mae: 1.8430 - val_loss: 1.8472 - val_mae: 1.8472\n",
      "Epoch 47/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7499 - mae: 1.7499 - val_loss: 1.7892 - val_mae: 1.7892\n",
      "Epoch 48/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6917 - mae: 1.6917 - val_loss: 1.7142 - val_mae: 1.7142\n",
      "Epoch 49/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6185 - mae: 1.6185 - val_loss: 1.6653 - val_mae: 1.6653\n",
      "Epoch 50/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5372 - mae: 1.5372 - val_loss: 1.6102 - val_mae: 1.6102\n",
      "Epoch 51/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.4760 - mae: 1.4760 - val_loss: 1.5487 - val_mae: 1.5487\n",
      "Epoch 52/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4826 - mae: 1.4826 - val_loss: 1.4650 - val_mae: 1.4650\n",
      "Epoch 53/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3892 - mae: 1.3892 - val_loss: 1.4293 - val_mae: 1.4293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3368 - mae: 1.3368 - val_loss: 1.3576 - val_mae: 1.3576\n",
      "Epoch 55/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2945 - mae: 1.2945 - val_loss: 1.3016 - val_mae: 1.3016\n",
      "Epoch 56/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1895 - mae: 1.1895 - val_loss: 1.2452 - val_mae: 1.2452\n",
      "Epoch 57/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1459 - mae: 1.1459 - val_loss: 1.1823 - val_mae: 1.1823\n",
      "Epoch 58/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0777 - mae: 1.0777 - val_loss: 1.1251 - val_mae: 1.1251\n",
      "Epoch 59/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0622 - mae: 1.0622 - val_loss: 1.0457 - val_mae: 1.0457\n",
      "Epoch 60/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9952 - mae: 0.9952 - val_loss: 0.9932 - val_mae: 0.9932\n",
      "Epoch 61/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9182 - mae: 0.9182 - val_loss: 0.9483 - val_mae: 0.9483\n",
      "Epoch 62/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8548 - mae: 0.8548 - val_loss: 0.8746 - val_mae: 0.8746\n",
      "Epoch 63/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8035 - mae: 0.8035 - val_loss: 0.8145 - val_mae: 0.8145\n",
      "Epoch 64/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7641 - mae: 0.7641 - val_loss: 0.7684 - val_mae: 0.7684\n",
      "Epoch 65/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7013 - mae: 0.7013 - val_loss: 0.7061 - val_mae: 0.7061\n",
      "Epoch 66/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6226 - mae: 0.6226 - val_loss: 0.6585 - val_mae: 0.6585\n",
      "Epoch 67/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6155 - mae: 0.6155 - val_loss: 0.6107 - val_mae: 0.6107\n",
      "Epoch 68/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5606 - mae: 0.5606 - val_loss: 0.5581 - val_mae: 0.5581\n",
      "Epoch 69/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5197 - mae: 0.5197 - val_loss: 0.5235 - val_mae: 0.5235\n",
      "Epoch 70/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4650 - mae: 0.4650 - val_loss: 0.4863 - val_mae: 0.4863\n",
      "Epoch 71/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4638 - mae: 0.4638 - val_loss: 0.4558 - val_mae: 0.4558\n",
      "Epoch 72/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4312 - mae: 0.4312 - val_loss: 0.4209 - val_mae: 0.4209\n",
      "Epoch 73/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3742 - mae: 0.3742 - val_loss: 0.4049 - val_mae: 0.4049\n",
      "Epoch 74/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3638 - mae: 0.3638 - val_loss: 0.3791 - val_mae: 0.3791\n",
      "Epoch 75/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3501 - mae: 0.3501 - val_loss: 0.3616 - val_mae: 0.3616\n",
      "Epoch 76/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3226 - mae: 0.3226 - val_loss: 0.3577 - val_mae: 0.3577\n",
      "Epoch 77/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3216 - mae: 0.3216 - val_loss: 0.3383 - val_mae: 0.3383\n",
      "Epoch 78/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2918 - mae: 0.2918 - val_loss: 0.3220 - val_mae: 0.3220\n",
      "Epoch 79/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2958 - mae: 0.2958 - val_loss: 0.3088 - val_mae: 0.3088\n",
      "Epoch 80/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3020 - mae: 0.3020 - val_loss: 0.2916 - val_mae: 0.2916\n",
      "Epoch 81/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2795 - mae: 0.2795 - val_loss: 0.2952 - val_mae: 0.2952\n",
      "Epoch 82/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2745 - mae: 0.2745 - val_loss: 0.2907 - val_mae: 0.2907\n",
      "Epoch 83/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2715 - mae: 0.2715 - val_loss: 0.2699 - val_mae: 0.2699\n",
      "Epoch 84/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2487 - mae: 0.2487 - val_loss: 0.2633 - val_mae: 0.2633\n",
      "Epoch 85/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2552 - mae: 0.2552 - val_loss: 0.2623 - val_mae: 0.2623\n",
      "Epoch 86/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2468 - mae: 0.2468 - val_loss: 0.2623 - val_mae: 0.2623\n",
      "Epoch 87/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2351 - mae: 0.2351 - val_loss: 0.2474 - val_mae: 0.2474\n",
      "Epoch 88/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2483 - mae: 0.2483 - val_loss: 0.2437 - val_mae: 0.2437\n",
      "Epoch 89/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2365 - mae: 0.2365 - val_loss: 0.2524 - val_mae: 0.2524\n",
      "Epoch 90/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2283 - mae: 0.2283 - val_loss: 0.2460 - val_mae: 0.2460\n",
      "Epoch 91/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2346 - mae: 0.2346 - val_loss: 0.2398 - val_mae: 0.2398\n",
      "Epoch 92/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2237 - mae: 0.2237 - val_loss: 0.2216 - val_mae: 0.2216\n",
      "Epoch 93/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2287 - mae: 0.2287 - val_loss: 0.2183 - val_mae: 0.2183\n",
      "Epoch 94/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2074 - mae: 0.2074 - val_loss: 0.2208 - val_mae: 0.2208\n",
      "Epoch 95/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2157 - mae: 0.2157 - val_loss: 0.2223 - val_mae: 0.2223\n",
      "Epoch 96/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2013 - mae: 0.2013 - val_loss: 0.2042 - val_mae: 0.2042\n",
      "Epoch 97/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2001 - mae: 0.2001 - val_loss: 0.2066 - val_mae: 0.2066\n",
      "Epoch 98/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1957 - mae: 0.1957 - val_loss: 0.1989 - val_mae: 0.1989\n",
      "Epoch 99/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1955 - mae: 0.1955 - val_loss: 0.2050 - val_mae: 0.2050\n",
      "Epoch 100/100\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2043 - mae: 0.2043 - val_loss: 0.1976 - val_mae: 0.1976\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Neural Network Model:\n",
      "Mean Squared Error: 0.18205524820737803\n",
      "Mean Absolute Error: 0.20183357062881582\n",
      "Random Forest Model:\n",
      "Mean Squared Error: 0.004652291380099839\n",
      "Mean Absolute Error: 0.04646677480719781\n",
      "XGBoost Model:\n",
      "Mean Squared Error: 0.5161495207106273\n",
      "Mean Absolute Error: 0.5109396886877536\n",
      "R-squared for Neural Network: 0.9982540007033596\n",
      "R-squared for Random Forest: 0.9999553822394168\n",
      "R-squared for XGBoost: 0.9950498724480851\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "# Load Data and Inspect\n",
    "inputTrip = \"TripA01\"\n",
    "dataTrip1 = pd.read_csv(f\"{inputTrip}.csv\", sep=\";\", encoding='unicode_escape')\n",
    "dfTrip1 = pd.DataFrame(dataTrip1)\n",
    "\n",
    "# Conforming Datasets\n",
    "def conform_datasets(nbOfTrips, pathToFiles, col_list=None):\n",
    "    dfSummerTrips = []\n",
    "    if not col_list:\n",
    "        col_list = []\n",
    "    inputTripsA = pathToFiles\n",
    "    for i in range(0, nbOfTrips):\n",
    "        dataTrip = pd.read_csv(f\"{inputTripsA}{(i+1):02}.csv\", sep=\";\", encoding='unicode_escape') \n",
    "        dfSummerTrips.append(pd.DataFrame(dataTrip))\n",
    "        if not col_list: \n",
    "            col_list = dfSummerTrips[i].columns.tolist()\n",
    "        elif set(col_list) != set(dfSummerTrips[i].columns.tolist()):\n",
    "            diff = list(set(col_list) - set(dfSummerTrips[i].columns.tolist()))\n",
    "            for item in diff:\n",
    "                col_list.remove(item)\n",
    "    \n",
    "    for i, trip in enumerate(dfSummerTrips):\n",
    "        dfSummerTrips[i] = trip[col_list]\n",
    "    return dfSummerTrips, col_list\n",
    "\n",
    "pathA = \"TripA\"\n",
    "dfSummerTrips, consistent_cols = conform_datasets(nbOfTrips=32, pathToFiles=pathA)\n",
    "\n",
    "# Feature Engineering\n",
    "def prepare_features(df_TripList, stepWidth, dropNan=False):\n",
    "    newfeatures = []\n",
    "    for i, trip_df in enumerate(df_TripList):\n",
    "        if dropNan:\n",
    "            trip_df = trip_df.dropna()\n",
    "            trip_df.index = range(len(trip_df))\n",
    "\n",
    "        dfLength = len(trip_df.index)\n",
    "        numRows  = dfLength // stepWidth\n",
    "        for i in range(0, numRows):\n",
    "            averageVals = trip_df.iloc[i*stepWidth:(i+1)*stepWidth].sum() \n",
    "            averageVals = averageVals / (1. * stepWidth)\n",
    "            featureList = averageVals.add_prefix('avrg_')\n",
    "            elevationDiff = trip_df.loc[(i+1)*stepWidth, 'Elevation [m]'] - trip_df.loc[i*stepWidth, 'Elevation [m]']\n",
    "            featureList['Elevation change'] = elevationDiff \n",
    "            featuresAtBeginningOfWindow = trip_df.loc[i*stepWidth, ['SoC [%]', 'displayed SoC [%]']] \n",
    "            featureList[\"Previous SoC\"] = featuresAtBeginningOfWindow['SoC [%]']\n",
    "            featureList[\"Previous displayed SoC\"] = featuresAtBeginningOfWindow['displayed SoC [%]']\n",
    "            featuresAtEndOfWindow = trip_df.loc[(i+1)*stepWidth, ['SoC [%]', 'displayed SoC [%]']] \n",
    "            featureList[\"Next SoC\"] = featuresAtEndOfWindow['SoC [%]']\n",
    "            featureList[\"Next displayed SoC\"] = featuresAtEndOfWindow['displayed SoC [%]']\n",
    "            newfeatures.append(featureList)    \n",
    "    \n",
    "    newDf = pd.DataFrame(newfeatures)\n",
    "    newDf = newDf.drop(columns=['avrg_SoC [%]', 'avrg_displayed SoC [%]', 'avrg_Time [s]', 'avrg_Elevation [m]'])\n",
    "    hasNaN = newDf.isnull().values.any()\n",
    "    return newDf\n",
    "\n",
    "newDf = prepare_features(dfSummerTrips, stepWidth=60)\n",
    "\n",
    "# Split and Normalize the features\n",
    "def split_TestTrain(df, scaler=None):\n",
    "    try:\n",
    "        X = df.drop(columns=['Next SoC', 'Previous displayed SoC', 'Next displayed SoC'])\n",
    "    except:\n",
    "        X = df\n",
    "    y = df['Next SoC'].to_numpy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    if not scaler:\n",
    "        scaler = StandardScaler().fit(X)\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "    return scaler, [X_train_scaled, y_train, X_train.index], [X_test_scaled, y_test, X_test.index]\n",
    "\n",
    "scalerSummerTrips, train_tuple, test_tuple = split_TestTrain(newDf)\n",
    "X_train_scaled, y_train, index_train = train_tuple\n",
    "X_test_scaled,  y_test,  index_test  = test_tuple\n",
    "\n",
    "# Model Building\n",
    "def fit_model_NN(X, Y, X_test, y_test):\n",
    "    model = Sequential([\n",
    "        Dense(10, activation='relu', name='layer1'),\n",
    "        Dense(1, activation='relu', name='layer2')\n",
    "     ])\n",
    "\n",
    "    loss_object = 'mean_absolute_error'\n",
    "    optimizer_object = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer_object,\n",
    "                  loss=loss_object,\n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    history = model.fit(X, Y, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred, model\n",
    "\n",
    "def fit_model_RandomForest(X, Y, X_test):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, Y)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred, model\n",
    "\n",
    "def fit_model_XGBoost(X, Y, X_test):\n",
    "    model = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 100)\n",
    "    model.fit(X, Y)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred, model\n",
    "\n",
    "# Train and Evaluate Models\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# Neural Network\n",
    "y_pred_nn, model_nn = fit_model_NN(X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "print(\"Neural Network Model:\")\n",
    "evaluate_model(y_test, y_pred_nn)\n",
    "\n",
    "# Random Forest\n",
    "y_pred_rf, model_rf = fit_model_RandomForest(X_train_scaled, y_train, X_test_scaled)\n",
    "print(\"Random Forest Model:\")\n",
    "evaluate_model(y_test, y_pred_rf)\n",
    "\n",
    "# XGBoost\n",
    "y_pred_xgb, model_xgb = fit_model_XGBoost(X_train_scaled, y_train, X_test_scaled)\n",
    "print(\"XGBoost Model:\")\n",
    "evaluate_model(y_test, y_pred_xgb)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate R-squared for Neural Network\n",
    "r2_nn = r2_score(y_test, y_pred_nn)\n",
    "print(\"R-squared for Neural Network:\", r2_nn)\n",
    "\n",
    "# Calculate R-squared for Random Forest\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(\"R-squared for Random Forest:\", r2_rf)\n",
    "\n",
    "# Calculate R-squared for XGBoost\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "print(\"R-squared for XGBoost:\", r2_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd7ab28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Battery Capacity (kWh) for all trips: 2.34071312690282\n",
      "Energy Consumption Rate (kW) for all trips: 0.13323686709612093\n",
      "Remaining Driving Time (Neural Network): 231.89837729242714 minutes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load Data and Inspect\n",
    "inputTrip = \"TripA\"\n",
    "data_sum = 0\n",
    "distance_sum = 0\n",
    "\n",
    "for i in range(1, 33):\n",
    "    dataTrip = pd.read_csv(f\"{inputTrip}{i:02}.csv\", sep=\";\", encoding='unicode_escape')\n",
    "    dataTrip['Battery Current [kW]'] = dataTrip['Battery Current [A]'] * dataTrip['Battery Voltage [V]'] / 1000\n",
    "    data_sum += np.trapz(dataTrip['Battery Current [kW]'], dataTrip['Time [s]']) / 3600\n",
    "    distance_sum += np.trapz(dataTrip['Velocity [km/h]'] / 3600, dataTrip['Time [s]'])\n",
    "energy_consumption_rate_kw = data_sum / distance_sum\n",
    "battery_capacity_kwh = data_sum/32\n",
    "\n",
    "# Print the calculated values\n",
    "print(\"Battery Capacity (kWh) for all trips:\", abs(battery_capacity_kwh))\n",
    "print(\"Energy Consumption Rate (kW) for all trips:\", abs(energy_consumption_rate_kw))\n",
    "\n",
    "def calculate_remaining_driving_time(predicted_soc, battery_capacity_kwh, energy_consumption_rate_kw):\n",
    "    remaining_charge_percentage = 100 - predicted_soc\n",
    "    remaining_energy_kwh = remaining_charge_percentage / 100 * battery_capacity_kwh\n",
    "    remaining_driving_time_hours = remaining_energy_kwh / energy_consumption_rate_kw\n",
    "    remaining_driving_time_minutes = remaining_driving_time_hours * 60\n",
    "    return remaining_driving_time_minutes\n",
    "\n",
    "# battery percent taken from dashboard\n",
    "soc=78\n",
    "# Calculate remaining driving time for each model\n",
    "remaining_driving_time = calculate_remaining_driving_time(soc, battery_capacity_kwh, energy_consumption_rate_kw)\n",
    "\n",
    "print(\"Remaining Driving Time (Neural Network):\", remaining_driving_time, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e7554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
